{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](Capture.PNG)\n",
    "\n",
    "Although we won't do the part where C's go directly into the final layer too because we're here for educational content, not minmaxing :flushed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['emma', 'olivia', 'ava', 'isabella', 'sophia', 'charlotte', 'mia', 'amelia']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read in words\n",
    "words = open('../2 - makemore/names.txt', 'r').read().splitlines()\n",
    "words[:8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32033"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1: 'a', 2: 'b', 3: 'c', 4: 'd', 5: 'e', 6: 'f', 7: 'g', 8: 'h', 9: 'i', 10: 'j', 11: 'k', 12: 'l', 13: 'm', 14: 'n', 15: 'o', 16: 'p', 17: 'q', 18: 'r', 19: 's', 20: 't', 21: 'u', 22: 'v', 23: 'w', 24: 'x', 25: 'y', 26: 'z', 0: '.'} \n",
      " {'a': 1, 'b': 2, 'c': 3, 'd': 4, 'e': 5, 'f': 6, 'g': 7, 'h': 8, 'i': 9, 'j': 10, 'k': 11, 'l': 12, 'm': 13, 'n': 14, 'o': 15, 'p': 16, 'q': 17, 'r': 18, 's': 19, 't': 20, 'u': 21, 'v': 22, 'w': 23, 'x': 24, 'y': 25, 'z': 26, '.': 0}\n"
     ]
    }
   ],
   "source": [
    "# Build the vocab of characters and mappings of char <-> ints\n",
    "chars = sorted(list(set(''.join(words))))\n",
    "stoi = {s:i+1 for i, s in enumerate(chars)} # string to integer\n",
    "stoi['.'] = 0\n",
    "itos = {i: s for s, i in stoi.items()} # int to string\n",
    "print(itos, '\\n', stoi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "emma\n",
      "... ------> e\n",
      "..e ------> m\n",
      ".em ------> m\n",
      "emm ------> a\n",
      "mma ------> .\n",
      "olivia\n",
      "... ------> o\n",
      "..o ------> l\n",
      ".ol ------> i\n",
      "oli ------> v\n",
      "liv ------> i\n",
      "ivi ------> a\n",
      "via ------> .\n",
      "ava\n",
      "... ------> a\n",
      "..a ------> v\n",
      ".av ------> a\n",
      "ava ------> .\n",
      "isabella\n",
      "... ------> i\n",
      "..i ------> s\n",
      ".is ------> a\n",
      "isa ------> b\n",
      "sab ------> e\n",
      "abe ------> l\n",
      "bel ------> l\n",
      "ell ------> a\n",
      "lla ------> .\n",
      "sophia\n",
      "... ------> s\n",
      "..s ------> o\n",
      ".so ------> p\n",
      "sop ------> h\n",
      "oph ------> i\n",
      "phi ------> a\n",
      "hia ------> .\n"
     ]
    }
   ],
   "source": [
    "# Building the dataset\n",
    "\n",
    "def generate_dataset(words, block_size, doprint=False):\n",
    "\t\"returns X, Y datasets based on words list\"\n",
    "\t#block_size: context length: how many characters do we take to predict the next one?\n",
    "\n",
    "\tX, Y = [], []\n",
    "\n",
    "\tfor w in words:\n",
    "\t\tif doprint:\n",
    "\t\t\tprint(w)\t\n",
    "\t\tcontext = [0] * block_size # this would make [0, 0, ...] based on block_size\n",
    "\n",
    "\t\tfor ch in w + '.': \n",
    "\t\t\tix = stoi[ch] # index of char\n",
    "\t\t\tX.append(context)\n",
    "\t\t\tY.append(ix)\n",
    "\t\t\t\n",
    "\t\t\tif doprint:\n",
    "\t\t\t\tprint(''.join(itos[i] for i in context), '------>', itos[ix])\n",
    "\t\t\tcontext = context[1:] + [ix] # [0,0,0] -> [0,0, ix] like a rolling effect\n",
    "\n",
    "\tX = torch.tensor(X)\n",
    "\tY = torch.tensor(Y)\n",
    "\treturn X, Y\n",
    "X, Y = generate_dataset(words[:5], 3, True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 3]) torch.int64 torch.Size([32]) torch.int64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor([[ 0,  0,  0],\n",
       "         [ 0,  0,  5],\n",
       "         [ 0,  5, 13],\n",
       "         [ 5, 13, 13],\n",
       "         [13, 13,  1],\n",
       "         [ 0,  0,  0],\n",
       "         [ 0,  0, 15],\n",
       "         [ 0, 15, 12],\n",
       "         [15, 12,  9],\n",
       "         [12,  9, 22],\n",
       "         [ 9, 22,  9],\n",
       "         [22,  9,  1],\n",
       "         [ 0,  0,  0],\n",
       "         [ 0,  0,  1],\n",
       "         [ 0,  1, 22],\n",
       "         [ 1, 22,  1],\n",
       "         [ 0,  0,  0],\n",
       "         [ 0,  0,  9],\n",
       "         [ 0,  9, 19],\n",
       "         [ 9, 19,  1],\n",
       "         [19,  1,  2],\n",
       "         [ 1,  2,  5],\n",
       "         [ 2,  5, 12],\n",
       "         [ 5, 12, 12],\n",
       "         [12, 12,  1],\n",
       "         [ 0,  0,  0],\n",
       "         [ 0,  0, 19],\n",
       "         [ 0, 19, 15],\n",
       "         [19, 15, 16],\n",
       "         [15, 16,  8],\n",
       "         [16,  8,  9],\n",
       "         [ 8,  9,  1]]),\n",
       " tensor([ 5, 13, 13,  1,  0, 15, 12,  9, 22,  9,  1,  0,  1, 22,  1,  0,  9, 19,\n",
       "          1,  2,  5, 12, 12,  1,  0, 19, 15, 16,  8,  9,  1,  0]))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(X.shape, X.dtype, Y.shape, Y.dtype)\n",
    "X, Y # Each X[n] maps to a Y[n], that's a training example. So you wanna take the X, predict the Y (via NN once again)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Embedding our inputs\n",
    "This is the first step of the NN -- basically, converting our indexes to some embedding.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.8650,  1.1346])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "C = torch.randn((27, 2)) # long chocolate bar \n",
    "C[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.8650,  1.1346])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F.one_hot(torch.tensor(5), num_classes=27).float() @ C # It's the same thing as indexing, because that's how matrix mult works, and how one hot encodes (remember, just, a vector of 0s  except for the 1 at index 5.) So there's multiple ways you can interpret this. For now, we'll use indexing because it's faster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.8650,  1.1346],\n",
       "        [ 1.4501, -1.1544],\n",
       "        [ 0.3911, -1.0933]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "C[[5,6,7]] # We can index multiple things at once, X here we come!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 3, 2])\n",
      "For example 13, the 2nd char index is 1, and that has an embedding of tensor([ 0.4246, -0.0144]), and we can see it's the same as C[1]=tensor([ 0.4246, -0.0144])\n"
     ]
    }
   ],
   "source": [
    "emb = C[X] # Can even do multidimensional indexing\n",
    "print(emb.shape)\n",
    "\"\"\"\n",
    "This gives us the embedding for every example of X (of which, each example has 3 inputs).\n",
    "\"\"\"\n",
    "print(f\"Ex: For example 13, the 2nd char index is {X[13, 2]}, and that has an embedding of {emb[13, 2]}, and we can see it's the same as {C[1]=}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Weights and Layers\n",
    "Look at the picture. This is the layer that'll get tanh'd -- the above embedding stuff is the look into C and embedding which, which will be our inputs to the NN "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (96x2 and 6x100)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[42], line 5\u001b[0m\n\u001b[0;32m      2\u001b[0m b1 \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mrandn(\u001b[39m100\u001b[39m)\n\u001b[0;32m      4\u001b[0m \u001b[39m# However!\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m emb \u001b[39m@\u001b[39;49m W1 \u001b[39m+\u001b[39m b1 \u001b[39m# Gives error since we can't multiply (32,3,2) by (6,100)! We have to convert the embed to a (32, 6) matrix.\u001b[39;00m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (96x2 and 6x100)"
     ]
    }
   ],
   "source": [
    "W1 = torch.randn((6, 100)) # as you can see from the embedding, we'll have 6 inputs per example. (3 chars and each char embedded to 2 things).\n",
    "b1 = torch.randn(100)\n",
    "\n",
    "# However!\n",
    "emb @ W1 + b1 # Gives error since we can't multiply (32,3,2) by (6,100)! We have to convert the embed to a (32, 6) matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 2])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 6])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(emb[:, 0, :].shape) # This'll get embedding of all the first character examples. \n",
    "\"\"\" Now, we'll get all of them in a sequence, and then concat their columns together.\"\"\"\n",
    "\n",
    "torch.cat([emb[:, 0, :], emb[:, 1, :], emb[:, 2, :]], 1).shape # And we want to concatenate along the '1' dimension (i.e column wise here). But it's not easily generalisable if we wanted more code blocks. So:\n",
    "\"\"\"OH SHIT! I JUST REALISED WHAT WAY THE DIMENSION NUMBER WORKS. LOL. FUCK ME.\n",
    "It's just, say you have a torch.Size([a,b,c,d]). a is dim 0, b is dim 1, c is dim 2...\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 3, 2])\n",
      "3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 6])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(emb.shape) # we unbind along index 1 to combine the way we want to.\n",
    "print(len(torch.unbind(emb, 1)))\n",
    "\n",
    "torch.cat(torch.unbind(emb, 1), 1).shape # Unbind here does the same thing as our whole emb sequence above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ----- Education ------\n",
    "# # However, we have more efficient way! :o view!\n",
    "a = torch.arange(18)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17]),\n",
       " tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8],\n",
       "         [ 9, 10, 11, 12, 13, 14, 15, 16, 17]]),\n",
       " tensor([[ 0,  1],\n",
       "         [ 2,  3],\n",
       "         [ 4,  5],\n",
       "         [ 6,  7],\n",
       "         [ 8,  9],\n",
       "         [10, 11],\n",
       "         [12, 13],\n",
       "         [14, 15],\n",
       "         [16, 17]]),\n",
       " tensor([[[ 0,  1],\n",
       "          [ 2,  3],\n",
       "          [ 4,  5]],\n",
       " \n",
       "         [[ 6,  7],\n",
       "          [ 8,  9],\n",
       "          [10, 11]],\n",
       " \n",
       "         [[12, 13],\n",
       "          [14, 15],\n",
       "          [16, 17]]]))"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.view(18), a.view(2,9), a.view(9,2), a.view(3,3,2) # They all work, and super quick! Just gotta be a*b*... = num of elements total."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 3, 2])\n",
      "tensor([[True, True, True, True, True, True],\n",
      "        [True, True, True, True, True, True],\n",
      "        [True, True, True, True, True, True],\n",
      "        [True, True, True, True, True, True],\n",
      "        [True, True, True, True, True, True],\n",
      "        [True, True, True, True, True, True],\n",
      "        [True, True, True, True, True, True],\n",
      "        [True, True, True, True, True, True],\n",
      "        [True, True, True, True, True, True],\n",
      "        [True, True, True, True, True, True],\n",
      "        [True, True, True, True, True, True],\n",
      "        [True, True, True, True, True, True],\n",
      "        [True, True, True, True, True, True],\n",
      "        [True, True, True, True, True, True],\n",
      "        [True, True, True, True, True, True],\n",
      "        [True, True, True, True, True, True],\n",
      "        [True, True, True, True, True, True],\n",
      "        [True, True, True, True, True, True],\n",
      "        [True, True, True, True, True, True],\n",
      "        [True, True, True, True, True, True],\n",
      "        [True, True, True, True, True, True],\n",
      "        [True, True, True, True, True, True],\n",
      "        [True, True, True, True, True, True],\n",
      "        [True, True, True, True, True, True],\n",
      "        [True, True, True, True, True, True],\n",
      "        [True, True, True, True, True, True],\n",
      "        [True, True, True, True, True, True],\n",
      "        [True, True, True, True, True, True],\n",
      "        [True, True, True, True, True, True],\n",
      "        [True, True, True, True, True, True],\n",
      "        [True, True, True, True, True, True],\n",
      "        [True, True, True, True, True, True]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[ 2.7268, -3.0981,  3.1197,  ...,  6.5318, -7.7704,  0.0571],\n",
       "        [ 2.2707, -2.2964,  4.6629,  ...,  5.1119, -7.6003, -0.6592],\n",
       "        [ 2.6195, -1.4434,  3.9820,  ...,  3.0401, -6.1684, -1.0681],\n",
       "        ...,\n",
       "        [-2.2184,  0.0373,  0.8352,  ...,  0.4229,  3.6632, -1.0233],\n",
       "        [-1.2713,  1.4442,  5.6576,  ..., -2.1889, -1.2700, -1.3892],\n",
       "        [ 1.2163,  0.8004,  1.0746,  ..., -2.6963,  4.0367, -1.6649]])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(emb.shape)\n",
    "print(emb.view(32, 6) ==  torch.cat(torch.unbind(emb, 1), 1)) # It 'views' it in the same way :o\n",
    "h = emb.view(32, 6) @ W1 + b1\n",
    "h\n",
    "\n",
    "####### --------------- Back to main ------------- ############ \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.9915, -0.9959,  0.9961,  ...,  1.0000, -1.0000,  0.0571],\n",
      "        [ 0.9789, -0.9800,  0.9998,  ...,  0.9999, -1.0000, -0.5779],\n",
      "        [ 0.9894, -0.8944,  0.9993,  ...,  0.9954, -1.0000, -0.7887],\n",
      "        ...,\n",
      "        [-0.9766,  0.0373,  0.6833,  ...,  0.3993,  0.9987, -0.7712],\n",
      "        [-0.8541,  0.8945,  1.0000,  ..., -0.9752, -0.8538, -0.8830],\n",
      "        [ 0.8386,  0.6642,  0.7912,  ..., -0.9909,  0.9994, -0.9309]])\n",
      "torch.Size([32, 100])\n"
     ]
    }
   ],
   "source": [
    "h = torch.tanh(emb.view(-1, 6) @ W1 + b1) # -1 same as emb.shape[0] (infers shit pytorch chad mode) just so we don't hardcode num of examples\n",
    "print(h)  # nums between -1, 1\n",
    "print(h.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----- Educational\n",
    "just to make sure we  broadcasting right! https://pytorch.org/docs/stable/notes/broadcasting.html\n",
    "\n",
    "Two tensors are “broadcastable” if the following rules hold:\n",
    "\n",
    "Each tensor has at least one dimension.\n",
    "\n",
    "When iterating over the dimension sizes, starting at the trailing dimension, the dimension sizes must either be equal, one of them is 1, or one of them does not exist."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([32, 100]), torch.Size([100]))"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(emb.view(-1, 6) @ W1).shape, b1.shape\n",
    "# 32, 100\n",
    "#  1 , 100 so it'll make this a row vector (it puts the 1 there), and then element wise additions over all 32 examples. We want this in this case -- same bias vector added to all rows of the matrix.\n",
    "# Good practice to make sure!!!!!"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Back to main!!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Second set of weights -- our final layer in this case!\n",
    "W2 = torch.randn((100, 27)) # 100 inputs, converts to 27 outputs (27 chars that come next)\n",
    "b2 = torch.randn(27)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 27])"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits = h @ W2 + b2 \n",
    "logits.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 27]) tensor(1.0000)\n"
     ]
    }
   ],
   "source": [
    "counts = logits.exp() \n",
    "probs = counts / counts.sum(1, keepdim=True)\n",
    "print(probs.shape,  probs[0].sum()) # Sanity check, sum of each row should equal 1 -- each row is prob dist of next word."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll get our loss function, simple simple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 5, 13, 13,  1,  0, 15, 12,  9, 22,  9,  1,  0,  1, 22,  1,  0,  9, 19,\n",
      "         1,  2,  5, 12, 12,  1,  0, 19, 15, 16,  8,  9,  1,  0]) \n",
      " tensor([4.0566e-08, 8.0922e-04, 1.1215e-04, 3.2266e-08, 3.4230e-10, 3.5458e-04,\n",
      "        7.3422e-02, 4.9846e-11, 1.0692e-06, 5.5262e-17, 3.8316e-07, 3.0864e-06,\n",
      "        5.4867e-09, 3.0371e-17, 6.2880e-12, 1.4152e-09, 1.8369e-10, 2.4629e-08,\n",
      "        5.3184e-08, 1.9197e-10, 1.4355e-12, 5.7702e-03, 2.1948e-11, 1.6727e-06,\n",
      "        1.9351e-04, 4.9451e-08, 3.5400e-01, 2.4573e-21, 3.6991e-11, 9.8634e-17,\n",
      "        1.7046e-05, 1.4627e-06])\n",
      "loss=tensor(18.6535)\n"
     ]
    }
   ],
   "source": [
    "print(Y, '\\n', probs[torch.arange(32), Y]) # The arange goes 0-31, so it'll return the 0-31st row of probs, and Y makes it so we index to the *correct* index, and get the probability of it. Some arw good like a 3.54e-01, but a lot are awful! Let's get the loss now.\n",
    "\n",
    "loss = -probs[torch.arange(32), Y].log().mean() # hardcoded 32 :(\n",
    "print(f'{loss=}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sum up of everything above, but respectably"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([228146, 3]), torch.Size([228146]))"
      ]
     },
     "execution_count": 254,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X, Y = generate_dataset(words, 3)\n",
    "X.shape, Y.shape # dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = torch.Generator().manual_seed(2147483647)\n",
    "def generate_parameters():\n",
    "\tC = torch.randn(27, 2, generator=g) # le embedding index thingy \n",
    "\tW1 = torch.randn((6, 100), generator=g)\n",
    "\tb1 = torch.randn(100, generator=g)\n",
    "\tW2 = torch.randn((100, 27), generator=g)\n",
    "\tb2 = torch.randn(27, generator=g)\n",
    "\tparameters = [C, W1, b1, W2, b2] # for easy summing parameters\n",
    "\n",
    "\tfor p in parameters:  # Turn on requires grad for our parameter matrices\n",
    "\t\tp.requires_grad = True\n",
    "\n",
    "\treturn parameters\n",
    "parameters = generate_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3481"
      ]
     },
     "execution_count": 274,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(p.nelement() for p in parameters) # num of parameters in total"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Educational moment!\n",
    "So, with cross entropy, the forward pass can be much more efficient, the backward pass can be much more efficient, and can be numerically well behaved\n",
    "```\n",
    "logits = torch.tensor([-50, 2, 3, 100])\n",
    "counts = logits.exp() # poggers time to convert logits to prob distrs!\n",
    "probs = counts / counts.sum()\n",
    "probs -> tensor([0., 0., 0., nan])\n",
    "```\n",
    "Uh oh! Basically, it goes way over our max positive limit (via exp, literally doing e^100). Small numbers are fine, and since you can +- any arbitrary constant to logits and get the same prob outputs due to the normalisation, cross_entropy basically does a thing where it picks out the max value number in the logits tensor, and subtracts it away so we don't get any sussy baka nans.\n",
    "\n",
    "Okay, I'm removing the code below and replacing it with F.cross_entropy now :( \n",
    "```\n",
    "\tcounts = logits.exp() # poggers time to convert logits to prob distrs!\n",
    "\tprobs = counts / counts.sum(1, keepdims=True)\n",
    "\tloss = -probs[torch.arange(32), Y].log().mean() # hardcoded 32 :(\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_pass(params, X):\n",
    "\tC, W1, b1, W2, b2 = params\n",
    "\t# Construct minibatch (of size 32)\n",
    "\tix = torch.randint(0, X.shape[0], (32,)) # 32 random ints from size of 0- training set\n",
    "\t\n",
    "\t# forward pass\n",
    "\temb = C[X[ix]] # (32,3,2) here\n",
    "\th = torch.tanh(emb.view(-1, 6) @ W1 + b1) # (32, 100)\n",
    "\tlogits = h @ W2 + b2 # (32, 27)\n",
    "\n",
    "\tloss = F.cross_entropy(logits, Y[ix]) # Does the epic normalisation stuff\n",
    "\t# print(f'{loss=}')\n",
    "\treturn logits, loss\n",
    "\n",
    "def train_model(parameters, X, Y):\n",
    "\t\"\"\" \n",
    "\tTHIS IS MINIBATCHED UP BTW!!!\n",
    "\tThe training section of your parameters -- you gradient descent down this mofo!\n",
    "\tThis changed a lot over the course of the video. Like, we have cross entropy instead of the default inefficient normalising way, minibatches, ...\n",
    "\tYeah.\n",
    "\n",
    "\tArgs:\n",
    "\t\tparameters (_type_): From generate_parameters()\n",
    "\t\t\"\"\"\n",
    "\tC, W1, b1, W2, b2 = parameters\n",
    "\tfor _ in range(10):\n",
    "\n",
    "\t\t# Forward pass -- this is minibatched!\n",
    "\t\tlogits, loss = forward_pass(parameters, X)\n",
    "\n",
    "\t\t# backward pass - zero grad, backprop\n",
    "\t\tfor p in parameters:\n",
    "\t\t\tp.grad = None\n",
    "\t\tloss.backward()\n",
    "\n",
    "\t\t# update\n",
    "\t\tfor p in parameters:\n",
    "\t\t\tp.data += -0.1 * p.grad\n",
    "\tprint(f'{loss=}') # This is the loss for the minibatch rn.\n",
    "\treturn parameters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss=tensor(7.8733, grad_fn=<NllLossBackward0>)\n"
     ]
    }
   ],
   "source": [
    "parameters = train_model(parameters, X, Y)\n",
    "C, W1, b1, W2, b2 = parameters # Just so we can get some fkin 'niceness' between karpathy's going through stuff lecture and us modularising it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss=tensor(11.0778, grad_fn=<NllLossBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# This is just a bit so we can see the whole training set loss and not just the training batch loss\n",
    "emb = C[X] # (X.shape[0],3,2) here -- whole set in this case\n",
    "h = torch.tanh(emb.view(-1, 6) @ W1 + b1) # (32, 100)\n",
    "logits = h @ W2 + b2 # (32, 27)\n",
    "\n",
    "loss = F.cross_entropy(logits, Y) # Does the epic normalisation stuff\n",
    "print(f'{loss=}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Educational time! Minibatches\n",
    "At the core -- even though minibatches only approximate the gradient (i.e not as reliable as the full training set), you can take a lot more steps, and it's worth it over the full training set that gets the gradient but you tkae a lot less steps.\n",
    "\n",
    "Basically, the way you minibatch is you make a range of numbers (of your minibatch size, like 32) between 0-training set size. And then you run the gradient descent on that batch as your 'training set' basically. And you just keep doing that.\n",
    "~44:00 mins in.\n",
    "```\n",
    "ix = torch.randint(0, 5, (32,)) # generates 32 numbers from 0-5. We'll use this idea for minibatches.\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trying to find the best learning rate\n",
    "This shit's gotta be so confusing for onlookers lmaooo. Okay, anyways. ~46 mins in. Wait. 46???? DUDE. IT'S BEEN LIKE HALF A FUCKING HOUR. GAAAAAAAH\n",
    "We'll see what learning rates are the best. Time to dismantle the code again :o\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = generate_parameters()\n",
    "\n",
    "lre = torch.linspace(-3, 0, 1000) # generates 1000 points equally distanced between -3, 0. But these will act as the exponentials of the actual things we're gonna plot.count\n",
    "lrs = 10**lre # exponential spacing :o "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss=tensor(2.6687, grad_fn=<NllLossBackward0>)\n"
     ]
    }
   ],
   "source": [
    "lri = []  # learning rates we used\n",
    "lossi = [] # losses due to that learning rate.\n",
    "for i in range(1000):\n",
    "\tC, W1, b1, W2, b2 = parameters\n",
    "\t# Forward pass -- this is minibatched!\n",
    "\t# Construct minibatch (of size 32)\n",
    "\tix = torch.randint(0, X.shape[0], (32,)) # 32 random ints from size of 0- training set\n",
    "\t\n",
    "\t# forward pass\n",
    "\tlogits, loss = forward_pass(parameters, X)\n",
    "\n",
    "\n",
    "\t# backward pass - zero grad, backprop\n",
    "\tfor p in parameters:\n",
    "\t\tp.grad = None\n",
    "\tloss.backward()\n",
    "\n",
    "\t# update\n",
    "\tlr = lrs[i]\n",
    "\tfor p in parameters:\n",
    "\t\tp.data +=  lr * p.grad\n",
    "\n",
    "\t# track stats\n",
    "\tlri.append(lr)\n",
    "\tlrs.append(loss.item())\n",
    "\n",
    "\n",
    "# print(f'{loss=}') # This is the loss for the minibatch rn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c8a31c3d3c58cfe49314f156da5c5377d35db16854b5a4a4800d645f76ea86e2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
